{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from keras.models import Model\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D,Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_size = 128\n",
    "#input_channels = 3\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "n_folds = 2\n",
    "training = True\n",
    "ensemble_voting = False  # If True, use voting for model ensemble, otherwise use averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_json(\"data/iceberg/train.json\")\n",
    "test = pd.read_json(\"data/iceberg/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n",
    "\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                          x_band2[:, :, :, np.newaxis],\n",
    "                          ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "target_train=train['is_iceberg']\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                         x_band2[:, :, :, np.newaxis],\n",
    "                         ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "id_test = test['id'].values\n",
    "\n",
    "del test; del x_band1; del x_band2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 25089     \n",
      "=================================================================\n",
      "Total params: 20,049,485\n",
      "Trainable params: 20,049,479\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define CNN Model Architecture\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "\n",
    "def Vgg19(img_dim=img_dim):\n",
    "    input_tensor = Input(shape=img_dim)\n",
    "    base_model = VGG19(include_top=False,\n",
    "                       weights='imagenet',\n",
    "                       input_shape=(img_height, img_width, img_channels))\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = Vgg19()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=1)\n",
    "fold_count = 0\n",
    "#y_full_test = []\n",
    "#thres_sum = np.zeros(2, np.float32)\n",
    "img_size = (img_height, img_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  12\n",
      "Training on 1283 samples\n",
      "Training target on 1283 samples\n",
      "Validating on 321 samples\n",
      "Epoch 1/1\n",
      "101s - loss: 0.4663 - acc: 0.7915 - val_loss: 4.3846 - val_acc: 0.6168\n",
      "Fold  13\n",
      "Training on 1283 samples\n",
      "Training target on 1283 samples\n",
      "Validating on 321 samples\n",
      "Epoch 1/1\n",
      "102s - loss: 0.4087 - acc: 0.7976 - val_loss: 1.9505 - val_acc: 0.7664\n",
      "Fold  14\n",
      "Training on 1283 samples\n",
      "Training target on 1283 samples\n",
      "Validating on 321 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "    fold_count += 1\n",
    "    print('Fold ', fold_count)   \n",
    "\n",
    "\n",
    "    def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                # Rotate 90\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                # flip vertically\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                # Rotate 180\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                # flip horizontally\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                # Rotate 90 counter-clockwise\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                # Rotate 180 and flip horizontally\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "    \n",
    "    df_train = X_train[train_index]\n",
    "    y_train = target_train[train_index]\n",
    "    #print(df_train[:3])\n",
    "    if training:\n",
    "        print('Training on {} samples'.format(len(df_train)))\n",
    "        print('Training target on {} samples'.format(len(y_train)))\n",
    "\n",
    "\n",
    "\n",
    "    def train_generator():\n",
    "        while True:\n",
    "            for start in range(0, len(df_train), batch_size):\n",
    "                x_batch = []\n",
    "                end = min(start + batch_size, len(df_train))\n",
    "                y_batch = y_train[start:end]\n",
    "                for img in df_train[start:end]:\n",
    "                    #img = cv2.imread('input/train-jpg/{}.jpg'.format(f))\n",
    "                    new_img = cv2.resize(img, img_size)\n",
    "                    new_img = augment(new_img, np.random.randint(6))\n",
    "                    x_batch.append(new_img)                    \n",
    "                x_batch = np.array(x_batch, np.float32)/ 255.\n",
    "                y_batch = np.array(y_batch, np.uint8)\n",
    "                yield x_batch, y_batch\n",
    "\n",
    "\n",
    "    df_valid = X_train[test_index]\n",
    "    y_valid = target_train[test_index]\n",
    "    #print(df_valid[:3])\n",
    "    print('Validating on {} samples'.format(len(df_valid)))\n",
    "\n",
    "\n",
    "    def valid_generator():\n",
    "        while True:\n",
    "            for start in range(0, len(df_valid), batch_size):\n",
    "                x_batch = []\n",
    "                end = min(start + batch_size, len(df_valid))\n",
    "                y_batch = y_valid[start:end]\n",
    "                for img in df_valid[start:end]:\n",
    "                    new_img = cv2.resize(img, img_size)\n",
    "                    x_batch.append(new_img)\n",
    "                x_batch = np.array(x_batch, np.float32)\n",
    "                y_batch = np.array(y_batch, np.uint8)\n",
    "                yield x_batch, y_batch\n",
    "\n",
    "    def test_generator(transformation):\n",
    "        while True:\n",
    "            for start in range(0, len(X_test), batch_size):\n",
    "                x_batch = []\n",
    "                end = min(start + batch_size, len(X_test))\n",
    "                for img in X_test[start:end]:\n",
    "                    new_img = cv2.resize(img, img_size)\n",
    "                    new_img = augment(img, transformation)\n",
    "                    x_batch.append(new_img)\n",
    "                x_batch = np.array(x_batch, np.float32)\n",
    "                yield x_batch\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               min_delta=1e-4),\n",
    "                 ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.1,\n",
    "                                   patience=2,\n",
    "                                   cooldown=2,\n",
    "                                   verbose=1),\n",
    "                 ModelCheckpoint(filepath='best_weights.fold_' + str(fold_count) + '.hdf5',\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True)]\n",
    "\n",
    "    model = model\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-4),metrics=['accuracy'])\n",
    "    \n",
    "    train_steps = len(df_train) / batch_size\n",
    "    valid_steps = len(df_valid) / batch_size\n",
    "    test_steps = len(X_test) / n_folds\n",
    "\n",
    "    if training:\n",
    "        model.fit_generator(generator=train_generator(),\n",
    "                            steps_per_epoch=train_steps,\n",
    "                            epochs=epochs,\n",
    "                            verbose=2,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=valid_generator(),\n",
    "                            validation_steps= valid_steps)\n",
    "\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_weights(filepath='best_weights.fold_' + str(fold_count) + '.hdf5')\n",
    "\n",
    "    p_valid = model.predict_generator(generator=valid_generator(),steps= valid_steps)\n",
    "    \n",
    "#     print('----------------------------------------')\n",
    "#     print('Running train evaluation on fold {}'.format(i))\n",
    "#     train_score = model.evaluate_generator(train_generator(), steps=train_steps)        \n",
    "#     print('Running validation evaluation on fold {}'.format(i))\n",
    "#     valid_score = model.evaluate_generator(valid_generator(), steps=valid_steps)\n",
    "#     print('----------------------------------------')   \n",
    "        \n",
    "#     print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n",
    "#                                                                             train_score[1], i))\n",
    "#     print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n",
    "#                                                                             valid_score[1], i))\n",
    "#     print('----------------------------------------')\n",
    "\n",
    "#     train_scores.append(train_score[1])\n",
    "#     valid_scores.append(valid_score[1])\n",
    "#     print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n",
    "#               (np.mean(train_scores), np.mean(valid_scores), i))\n",
    "#     print('----------------------------------------')\n",
    "    \n",
    "#     print('Running test predictions with fold {}'.format(i))        \n",
    "#     preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "#                                               steps=test_steps, verbose=1)[:, -1]\n",
    "#     print(preds_test_fold)\n",
    "\n",
    "#     preds_test += preds_test_fold\n",
    "\n",
    "#     print('\\n\\n')\n",
    "\n",
    "#     i += 1\n",
    "\n",
    "#     if i <= n_fold:\n",
    "#         print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "#     else:\n",
    "#         print('Finished training!')\n",
    "    \n",
    "\n",
    "    \n",
    "#     # 6-fold TTA\n",
    "#     number_of_times = 2\n",
    "#     p_full_test = []\n",
    "#     for i in range(number_of_times):\n",
    "#         p_test = model.predict_generator(generator=test_generator(transformation=i),steps= test_steps)\n",
    "#         p_full_test.append(p_test)\n",
    "        \n",
    "#     preds = p_full_test/ number_of_times\n",
    "\n",
    "#     p_test = np.array(p_full_test[0])\n",
    "#     for i in range(1, 6):\n",
    "#         p_test += np.array(p_full_test[i])\n",
    "#     p_test /= 6\n",
    "\n",
    "#     y_full_test.append(p_test)\n",
    "\n",
    "# result = np.array(y_full_test[0])\n",
    "# if ensemble_voting:\n",
    "#     for f in range(len(y_full_test[0])):  # For each file\n",
    "#         for tag in range(17):  # For each tag\n",
    "#             preds = []\n",
    "#             for fold in range(n_folds):  # For each fold\n",
    "#                 preds.append(y_full_test[fold][f][tag])\n",
    "#             pred = Counter(preds).most_common(1)[0][0]  # Most common tag prediction among folds\n",
    "#             result[f][tag] = pred\n",
    "# else:\n",
    "#     for fold in range(1, n_folds):\n",
    "#         result += np.array(y_full_test[fold])\n",
    "#     result /= n_folds\n",
    "# result = pd.DataFrame(result, columns=labels)\n",
    "\n",
    "# preds = []\n",
    "# thres = (thres_sum / n_folds).tolist()\n",
    "\n",
    "# for i in result.shape[0]:\n",
    "#     a = result.ix[[i]]\n",
    "#     a = a.apply(lambda x: x > thres, axis=1)\n",
    "#     a = a.transpose()\n",
    "#     a = a.loc[a[i] == True]\n",
    "#     ' '.join(list(a.index))\n",
    "#     preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['is_iceberg'] = p_valid\n",
    "#X_test.to_csv('submission.csv', index=False)\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
