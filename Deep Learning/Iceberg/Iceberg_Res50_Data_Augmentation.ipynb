{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Model\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_json(\"data/iceberg/train.json\")\n",
    "test = pd.read_json(\"data/iceberg/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n",
    "\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                          x_band2[:, :, :, np.newaxis],\n",
    "                          ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "target_train=train['is_iceberg']\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                         x_band2[:, :, :, np.newaxis],\n",
    "                         ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "id_test = test['id'].values\n",
    "\n",
    "del test; del x_band1; del x_band2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 197, 197, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_573 (Bat (None, 197, 197, 3)       12        \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 26,211,213\n",
      "Trainable params: 26,158,087\n",
      "Non-trainable params: 53,126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define CNN Model Architecture (Kaggle can't access the weights file)\n",
    "img_height = 197\n",
    "img_width = 197\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "\n",
    "def res50(img_dim=img_dim):\n",
    "    input_tensor = Input(shape=img_dim)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(197,197,3))\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs = input_tensor, outputs = predictions)\n",
    "   # model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    #for layer in base_model.layers:\n",
    "         #layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = res50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the image size to fit Res50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "new_shape = (197,197,3)\n",
    "X_train_new = np.empty(shape=(X_train.shape[0],)+new_shape)\n",
    "for idx in range(X_train.shape[0]):\n",
    "    X_train_new[idx] = scipy.misc.imresize(X_train[idx], new_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "new_shape = (197,197,3)\n",
    "X_test_new = np.empty(shape=(X_test.shape[0],)+new_shape)\n",
    "for idx in range(X_test.shape[0]):\n",
    "    X_test_new[idx] = scipy.misc.imresize(X_test[idx], new_shape)\n",
    "    \n",
    "#X_test_new /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model and predict\n",
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n",
    "        \n",
    "    train_scores = []; valid_scores = []\n",
    "    preds_test = 0  \n",
    "\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x[train_index]; x_valid = x[test_index]\n",
    "        y_train = y[train_index]; y_valid = y[test_index]\n",
    "\n",
    "\n",
    "        \n",
    "        #batch_size=64\n",
    "        # Define the image transformations here\n",
    "        train_gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10,\n",
    "                                 rescale=1./255,\n",
    "                                 )\n",
    "        valid_gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10,\n",
    "                                 rescale=1./255,\n",
    "                                )\n",
    "        #test_gen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "          \n",
    "        model = model\n",
    "\n",
    "        model.fit_generator(train_gen.flow(x_train, y_train, batch_size=32),\n",
    "                            steps_per_epoch=len(x_train) / 32, epochs=epochs, \n",
    "                            callbacks=callbacks, validation_data= valid_gen.flow(x_valid, y_valid, batch_size=32),\n",
    "                           validation_steps = valid_steps)\n",
    "\n",
    "        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n",
    "\n",
    "        \n",
    "        print('----------------------------------------')\n",
    "        print('Running train evaluation on fold {}'.format(i))\n",
    "        train_score = model.evaluate_generator(train_gen.flow(x_valid, y_valid, batch_size=32), steps=train_steps)        \n",
    "        print('Running validation evaluation on fold {}'.format(i))\n",
    "        valid_score = model.evaluate_generator(valid_gen.flow(x_valid, y_valid, batch_size=32), steps=valid_steps)\n",
    "        print('----------------------------------------')   \n",
    "        \n",
    "        print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n",
    "                                                                            train_score[1], i))\n",
    "        print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n",
    "                                                                            valid_score[1], i))\n",
    "        print('----------------------------------------')\n",
    "\n",
    "        train_scores.append(train_score[1])\n",
    "        valid_scores.append(valid_score[1])\n",
    "        print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n",
    "              (np.mean(train_scores), np.mean(valid_scores), i))\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "        #Getting test scores\n",
    "        print('Running test predictions with fold {}'.format(i)) \n",
    "        temp_test = model.predict(test,batch_size = 32, verbose=1)\n",
    "        preds_test +=temp_test.reshape(temp_test.shape[0])\n",
    "        \n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "    \n",
    "    \n",
    "    return preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.6243 - acc: 0.6430Epoch 00000: val_loss improved from inf to 0.87212, saving model to inception.fold_1.hdf5\n",
      "34/33 [==============================] - 63s - loss: 0.6194 - acc: 0.6466 - val_loss: 0.8721 - val_acc: 0.5383\n",
      "Epoch 2/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.3507 - acc: 0.8277Epoch 00001: val_loss did not improve\n",
      "34/33 [==============================] - 38s - loss: 0.3601 - acc: 0.8215 - val_loss: 6.7623 - val_acc: 0.5607\n",
      "Epoch 3/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.3249 - acc: 0.8513\n",
      "Epoch 00002: reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 00002: val_loss did not improve\n",
      "34/33 [==============================] - 47s - loss: 0.3193 - acc: 0.8556 - val_loss: 7.2607 - val_acc: 0.5495\n",
      "Epoch 4/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.2919 - acc: 0.8627Epoch 00003: val_loss did not improve\n",
      "34/33 [==============================] - 38s - loss: 0.2893 - acc: 0.8644 - val_loss: 7.5318 - val_acc: 0.5327\n",
      "Epoch 5/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.8608\n",
      "Epoch 00004: reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 00004: val_loss did not improve\n",
      "34/33 [==============================] - 38s - loss: 0.2681 - acc: 0.8604 - val_loss: 7.6222 - val_acc: 0.5271\n",
      "Epoch 00004: early stopping\n",
      "----------------------------------------\n",
      "Running train evaluation on fold 1\n",
      "Running validation evaluation on fold 1\n",
      "----------------------------------------\n",
      "Train loss: 0.87172\n",
      " Train acc: 0.53832 for fold 1\n",
      "Valid loss: 0.87182\n",
      " Valid acc: 0.53832 for fold 1\n",
      "----------------------------------------\n",
      "Avg Train Acc: 0.53832\n",
      "Avg Valid Acc: 0.53832 after 1 folds\n",
      "----------------------------------------\n",
      "Running test predictions with fold 1\n",
      "8424/8424 [==============================] - 98s    \n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 2\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.7652Epoch 00000: val_loss improved from inf to 1.81380, saving model to inception.fold_2.hdf5\n",
      "34/33 [==============================] - 39s - loss: 0.4518 - acc: 0.7630 - val_loss: 1.8138 - val_acc: 0.5121\n",
      "Epoch 2/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.7576Epoch 00001: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4403 - acc: 0.7624 - val_loss: 4.2121 - val_acc: 0.5047\n",
      "Epoch 3/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.7595\n",
      "Epoch 00002: reducing learning rate to 1e-07.\n",
      "Epoch 00002: val_loss did not improve\n",
      "34/33 [==============================] - 38s - loss: 0.4434 - acc: 0.7598 - val_loss: 7.1917 - val_acc: 0.4991\n",
      "Epoch 4/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4208 - acc: 0.7708Epoch 00003: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4184 - acc: 0.7730 - val_loss: 7.6825 - val_acc: 0.5234\n",
      "Epoch 5/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4358 - acc: 0.7689Epoch 00004: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4353 - acc: 0.7712 - val_loss: 7.8632 - val_acc: 0.5121\n",
      "Epoch 00004: early stopping\n",
      "----------------------------------------\n",
      "Running train evaluation on fold 2\n",
      "Running validation evaluation on fold 2\n",
      "----------------------------------------\n",
      "Train loss: 1.81393\n",
      " Train acc: 0.51215 for fold 2\n",
      "Valid loss: 1.81312\n",
      " Valid acc: 0.51215 for fold 2\n",
      "----------------------------------------\n",
      "Avg Train Acc: 0.52523\n",
      "Avg Valid Acc: 0.52523 after 2 folds\n",
      "----------------------------------------\n",
      "Running test predictions with fold 2\n",
      "8424/8424 [==============================] - 89s    \n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 3\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.7462Epoch 00000: val_loss improved from inf to 3.86072, saving model to inception.fold_3.hdf5\n",
      "34/33 [==============================] - 40s - loss: 0.4634 - acc: 0.7453 - val_loss: 3.8607 - val_acc: 0.5412\n",
      "Epoch 2/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.7737Epoch 00001: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4388 - acc: 0.7740 - val_loss: 6.4721 - val_acc: 0.5431\n",
      "Epoch 3/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4264 - acc: 0.7699Epoch 00002: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4359 - acc: 0.7641 - val_loss: 7.6968 - val_acc: 0.5225\n",
      "Epoch 4/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.7642Epoch 00003: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4315 - acc: 0.7648 - val_loss: 7.5157 - val_acc: 0.5337\n",
      "Epoch 5/50\n",
      "33/33 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.7670Epoch 00004: val_loss did not improve\n",
      "34/33 [==============================] - 39s - loss: 0.4333 - acc: 0.7676 - val_loss: 7.1535 - val_acc: 0.5562\n",
      "Epoch 00004: early stopping\n",
      "----------------------------------------\n",
      "Running train evaluation on fold 3\n",
      "Running validation evaluation on fold 3\n",
      "----------------------------------------\n",
      "Train loss: 3.86085\n",
      " Train acc: 0.54120 for fold 3\n",
      "Valid loss: 3.85965\n",
      " Valid acc: 0.54120 for fold 3\n",
      "----------------------------------------\n",
      "Avg Train Acc: 0.53056\n",
      "Avg Valid Acc: 0.53056 after 3 folds\n",
      "----------------------------------------\n",
      "Running test predictions with fold 3\n",
      "8424/8424 [==============================] - 89s    \n",
      "\n",
      "\n",
      "\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "n_fold = 3\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "prediction = train_model(model, batch_size, epochs, img_size, X_train_new, \n",
    "                                target_train, X_test_new, n_fold, kf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id': id_test, 'is_iceberg': prediction.reshape((prediction.shape[0]))})\n",
    "submit.to_csv('./submission_inception.csv', index=False)\n",
    "#submit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
