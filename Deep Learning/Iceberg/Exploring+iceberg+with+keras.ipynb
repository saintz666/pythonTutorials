{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate and Reshape\n",
    "Here we load the data and then combine the two bands and recombine them into a single image/tensor for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_format(in_path):\n",
    "    out_df = pd.read_json(in_path)\n",
    "    out_images = out_df.apply(lambda c_row: [np.stack([c_row['band_1'],c_row['band_2']], -1).reshape((75,75,2))],1)\n",
    "    out_images = np.stack(out_images).squeeze()\n",
    "    return out_df, out_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = 'data/iceberg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (1604, 5) loaded (1604, 75, 75, 2)\n",
      "testing (8424, 4) loaded (8424, 75, 75, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>[-31.115002, -32.274887, -34.369637, -36.11268...</td>\n",
       "      <td>[-29.176804, -31.115047, -31.115091, -28.75314...</td>\n",
       "      <td>f3dc5422</td>\n",
       "      <td>42.518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>[-24.579832, -21.058052, -19.792459, -21.58472...</td>\n",
       "      <td>[-31.127012, -30.600475, -29.1889, -29.188946,...</td>\n",
       "      <td>f29ff564</td>\n",
       "      <td>42.5222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[-15.342882, -19.038483, -23.608122, -17.25976...</td>\n",
       "      <td>[-26.802034, -28.580906, -28.194857, -25.60223...</td>\n",
       "      <td>4b5201f0</td>\n",
       "      <td>39.6535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "1441  [-31.115002, -32.274887, -34.369637, -36.11268...   \n",
       "939   [-24.579832, -21.058052, -19.792459, -21.58472...   \n",
       "285   [-15.342882, -19.038483, -23.608122, -17.25976...   \n",
       "\n",
       "                                                 band_2        id inc_angle  \\\n",
       "1441  [-29.176804, -31.115047, -31.115091, -28.75314...  f3dc5422    42.518   \n",
       "939   [-31.127012, -30.600475, -29.1889, -29.188946,...  f29ff564   42.5222   \n",
       "285   [-26.802034, -28.580906, -28.194857, -25.60223...  4b5201f0   39.6535   \n",
       "\n",
       "      is_iceberg  \n",
       "1441           0  \n",
       "939            0  \n",
       "285            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, train_images = load_and_format(os.path.join(base_path, 'train.json'))\n",
    "print('training', train_df.shape, 'loaded', train_images.shape)\n",
    "test_df, test_images = load_and_format(os.path.join(base_path, 'test.json'))\n",
    "print('testing', test_df.shape, 'loaded', test_images.shape)\n",
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (802, 75, 75, 2) (802, 2)\n",
      "Validation (802, 75, 75, 2) (802, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images,\n",
    "                                                   to_categorical(train_df['is_iceberg']),\n",
    "                                                    random_state = 2017,\n",
    "                                                    test_size = 0.5\n",
    "                                                   )\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Validation', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 75, 75, 2)         8         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 73, 73, 8)         152       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 25,002\n",
      "Trainable params: 24,998\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, MaxPooling2D, GlobalMaxPooling2D, Dense\n",
    "simple_cnn = Sequential()\n",
    "simple_cnn.add(BatchNormalization(input_shape = (75, 75, 2)))\n",
    "for i in range(4):\n",
    "    simple_cnn.add(Conv2D(8*2**i, kernel_size = (3,3)))\n",
    "    simple_cnn.add(MaxPooling2D((2,2)))\n",
    "simple_cnn.add(GlobalMaxPooling2D())\n",
    "simple_cnn.add(Dropout(0.5))\n",
    "simple_cnn.add(Dense(8))\n",
    "simple_cnn.add(Dense(2, activation = 'softmax'))\n",
    "simple_cnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 802 samples, validate on 802 samples\n",
      "Epoch 1/10\n",
      "802/802 [==============================] - 37s - loss: 0.6945 - acc: 0.5810 - val_loss: 1.4264 - val_acc: 0.5798\n",
      "Epoch 2/10\n",
      "802/802 [==============================] - 0s - loss: 0.5861 - acc: 0.6708 - val_loss: 0.5075 - val_acc: 0.7805\n",
      "Epoch 3/10\n",
      "802/802 [==============================] - 0s - loss: 0.5345 - acc: 0.7307 - val_loss: 0.4851 - val_acc: 0.6995\n",
      "Epoch 4/10\n",
      "802/802 [==============================] - 0s - loss: 0.4534 - acc: 0.7631 - val_loss: 0.4025 - val_acc: 0.8142\n",
      "Epoch 5/10\n",
      "802/802 [==============================] - 0s - loss: 0.3878 - acc: 0.8167 - val_loss: 0.5080 - val_acc: 0.7544\n",
      "Epoch 6/10\n",
      "802/802 [==============================] - 0s - loss: 0.4074 - acc: 0.8067 - val_loss: 0.3726 - val_acc: 0.8354\n",
      "Epoch 7/10\n",
      "802/802 [==============================] - 0s - loss: 0.3727 - acc: 0.8267 - val_loss: 0.3989 - val_acc: 0.7930\n",
      "Epoch 8/10\n",
      "802/802 [==============================] - 0s - loss: 0.3350 - acc: 0.8404 - val_loss: 0.3687 - val_acc: 0.8491\n",
      "Epoch 9/10\n",
      "802/802 [==============================] - 0s - loss: 0.2840 - acc: 0.8815 - val_loss: 0.3565 - val_acc: 0.8466\n",
      "Epoch 10/10\n",
      "802/802 [==============================] - 0s - loss: 0.2606 - acc: 0.8903 - val_loss: 0.3405 - val_acc: 0.8441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5cfe704e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions\n",
    "Here we make predictions on the output and export the CSV so we can submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = simple_cnn.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7463</th>\n",
       "      <td>e3588c75</td>\n",
       "      <td>0.441332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>4caff066</td>\n",
       "      <td>0.017132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>753f66cc</td>\n",
       "      <td>0.010311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_iceberg\n",
       "7463  e3588c75    0.441332\n",
       "4592  4caff066    0.017132\n",
       "4119  753f66cc    0.010311"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = test_df[['id']].copy()\n",
    "pred_df['is_iceberg'] = test_predictions[:,1]\n",
    "pred_df.to_csv('predictions.csv', index = False)\n",
    "pred_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
