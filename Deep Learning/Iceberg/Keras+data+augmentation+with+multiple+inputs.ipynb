{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data and process data\n",
    "data_dir = \"data/iceberg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    train = pd.read_json(data_dir+\"train.json\")\n",
    "    test = pd.read_json(data_dir+\"test.json\")\n",
    "    # Fill 'na' angles with zero\n",
    "    train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "    train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "    test.inc_angle = test.inc_angle.replace('na', 0)\n",
    "    test.inc_angle = test.inc_angle.astype(float).fillna(0.0)\n",
    "    return train, test\n",
    "\n",
    "train, test = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process data into images\n",
    "def process_images(df):\n",
    "    X_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\n",
    "    X_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\n",
    "    # Merge bands and add another band as the mean of Band 1 and Band 2 (useful for the ImageDataGenerator later)\n",
    "    imgs = np.concatenate([X_band1[:, :, :, np.newaxis]\n",
    "                            , X_band2[:, :, :, np.newaxis]\n",
    "                            ,((X_band1+X_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = process_images(train)\n",
    "X_test = process_images(test)\n",
    "\n",
    "X_angle_train = np.array(train.inc_angle)\n",
    "X_angle_test = np.array(test.inc_angle)\n",
    "y_train = np.array(train[\"is_iceberg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train and validation split, 75% of data used in training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                    X_angle_train, y_train, random_state=666, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a basic CNN\n",
    "Using keras functional API to concatenate the angle input and convolutional model of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, concatenate, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D\n",
    "\n",
    "def simple_cnn():\n",
    "    pic_input = Input(shape=(75, 75, 3))\n",
    "    ang_input = Input(shape=(1,))\n",
    "\n",
    "    cnn = BatchNormalization()(pic_input)\n",
    "    for i in range(4):\n",
    "        cnn = Conv2D(8*2**i, kernel_size = (3,3), activation='relu')(cnn)\n",
    "        cnn = MaxPooling2D((2,2))(cnn)\n",
    "    cnn = GlobalMaxPooling2D()(cnn)\n",
    "    cnn = concatenate([cnn,ang_input])\n",
    "    cnn = Dense(32,activation='relu')(cnn)\n",
    "    cnn = Dense(1, activation = 'sigmoid')(cnn)\n",
    "\n",
    "    simple_cnn = Model(inputs=[pic_input,ang_input],outputs=cnn)\n",
    "\n",
    "    simple_cnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return simple_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create ImageDataGenerator\n",
    "Create a standard keras ImageDataGenerator, and then use a helper function to return multiple inputs as a list along with the y values necessary to train using fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "gen_flow = gen_flow_for_two_inputs(X_train, X_angle_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/18 [==============================] - 2s - loss: 0.8464 - acc: 0.6317 - val_loss: 4.0281 - val_acc: 0.5112\n",
      "Epoch 2/20\n",
      "19/18 [==============================] - 2s - loss: 0.5224 - acc: 0.7230 - val_loss: 6.3940 - val_acc: 0.5112\n",
      "Epoch 3/20\n",
      "19/18 [==============================] - 2s - loss: 0.5136 - acc: 0.7327 - val_loss: 6.5572 - val_acc: 0.5112\n",
      "Epoch 4/20\n",
      "19/18 [==============================] - 2s - loss: 0.4785 - acc: 0.7757 - val_loss: 4.9697 - val_acc: 0.5112\n",
      "Epoch 5/20\n",
      "19/18 [==============================] - 2s - loss: 0.4544 - acc: 0.7714 - val_loss: 3.7355 - val_acc: 0.5112\n",
      "Epoch 6/20\n",
      "19/18 [==============================] - 2s - loss: 0.4743 - acc: 0.7830 - val_loss: 1.4382 - val_acc: 0.5212\n",
      "Epoch 7/20\n",
      "19/18 [==============================] - 2s - loss: 0.4724 - acc: 0.7648 - val_loss: 1.3382 - val_acc: 0.5187\n",
      "Epoch 8/20\n",
      "19/18 [==============================] - 2s - loss: 0.4134 - acc: 0.8153 - val_loss: 0.9444 - val_acc: 0.5486\n",
      "Epoch 9/20\n",
      "19/18 [==============================] - 2s - loss: 0.3858 - acc: 0.8176 - val_loss: 0.4525 - val_acc: 0.7781\n",
      "Epoch 10/20\n",
      "19/18 [==============================] - 2s - loss: 0.3960 - acc: 0.8232 - val_loss: 0.5862 - val_acc: 0.6534\n",
      "Epoch 11/20\n",
      "19/18 [==============================] - 2s - loss: 0.3642 - acc: 0.8293 - val_loss: 0.4851 - val_acc: 0.7232\n",
      "Epoch 12/20\n",
      "19/18 [==============================] - 2s - loss: 0.3659 - acc: 0.8217 - val_loss: 0.3906 - val_acc: 0.8279\n",
      "Epoch 13/20\n",
      "19/18 [==============================] - 2s - loss: 0.3621 - acc: 0.8250 - val_loss: 0.4324 - val_acc: 0.7756\n",
      "Epoch 14/20\n",
      "19/18 [==============================] - 2s - loss: 0.3720 - acc: 0.8314 - val_loss: 0.3802 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "19/18 [==============================] - 2s - loss: 0.4191 - acc: 0.7919 - val_loss: 0.3473 - val_acc: 0.8579\n",
      "Epoch 16/20\n",
      "19/18 [==============================] - 2s - loss: 0.3328 - acc: 0.8440 - val_loss: 0.3447 - val_acc: 0.8279\n",
      "Epoch 17/20\n",
      "19/18 [==============================] - 2s - loss: 0.3489 - acc: 0.8392 - val_loss: 0.3528 - val_acc: 0.8429\n",
      "Epoch 18/20\n",
      "19/18 [==============================] - 2s - loss: 0.3284 - acc: 0.8553 - val_loss: 0.3586 - val_acc: 0.8229\n",
      "Epoch 19/20\n",
      "19/18 [==============================] - 2s - loss: 0.3552 - acc: 0.8267 - val_loss: 0.3205 - val_acc: 0.8653\n",
      "Epoch 20/20\n",
      "19/18 [==============================] - 2s - loss: 0.3836 - acc: 0.8141 - val_loss: 0.4004 - val_acc: 0.8130\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = simple_cnn()\n",
    "\n",
    "# Fit the model using our generator defined above\n",
    "history = model.fit_generator(gen_flow, validation_data=([X_valid, X_angle_valid], y_valid),\n",
    "                    steps_per_epoch=len(X_train) / batch_size, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>49c34c2b</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7947</th>\n",
       "      <td>6a6f3484</td>\n",
       "      <td>0.212221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>005d1a8d</td>\n",
       "      <td>0.940626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_iceberg\n",
       "6345  49c34c2b    0.000086\n",
       "7947  6a6f3484    0.212221\n",
       "3081  005d1a8d    0.940626"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "test_predictions = model.predict([X_test,X_angle_test])\n",
    "\n",
    "# Create .csv\n",
    "pred_df = test[['id']].copy()\n",
    "pred_df['is_iceberg'] = test_predictions\n",
    "pred_df.to_csv('predictions.csv', index = False)\n",
    "pred_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
