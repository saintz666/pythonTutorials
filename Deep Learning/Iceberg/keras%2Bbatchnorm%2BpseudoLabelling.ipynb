{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, MaxPooling2D, Flatten, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train = pd.read_json(\"data/iceberg/train.json\")\n",
    "test  = pd.read_json(\"data/iceberg/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "Test = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['is_iceberg']\n",
    "ID = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,target,test_size=0.25,stratify=target,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(BatchNormalization(input_shape=(75,75,3)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "model.add(Dense(64)) #512\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "check = ModelCheckpoint(\"weights.{epoch:02d}-{val_acc:.5f}.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37/37 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9417Epoch 00000: val_acc did not improve\n",
      "38/37 [==============================] - 1s - loss: 0.1379 - acc: 0.9419 - val_loss: 0.2284 - val_acc: 0.9027\n",
      "Epoch 2/5\n",
      "37/37 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9527Epoch 00001: val_acc did not improve\n",
      "38/37 [==============================] - 1s - loss: 0.1219 - acc: 0.9526 - val_loss: 0.2504 - val_acc: 0.8953\n",
      "Epoch 3/5\n",
      "37/37 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9392Epoch 00002: val_acc did not improve\n",
      "38/37 [==============================] - 1s - loss: 0.1380 - acc: 0.9408 - val_loss: 0.2922 - val_acc: 0.8803\n",
      "Epoch 4/5\n",
      "37/37 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9510Epoch 00003: val_acc did not improve\n",
      "38/37 [==============================] - 1s - loss: 0.1378 - acc: 0.9523 - val_loss: 0.2961 - val_acc: 0.8803\n",
      "Epoch 5/5\n",
      "37/37 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9476Epoch 00004: val_acc did not improve\n",
      "38/37 [==============================] - 1s - loss: 0.1199 - acc: 0.9490 - val_loss: 0.2880 - val_acc: 0.9002\n",
      "Epoch 00032: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40b8b82da0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),steps_per_epoch=len(x_train)/32,epochs=5,callbacks=[check,early],validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8288/8424 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = ID\n",
    "submission['is_iceberg'] = pred\n",
    "submission.to_csv('submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pseudo = model.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_trn = 0\n",
    "i_test = 0\n",
    "\n",
    "# iterate through 800 mini-batch\n",
    "num_iter = 600*2\n",
    "# mini-batch size\n",
    "size_trn = 48\n",
    "size_test = 16\n",
    "num_batch_per_epoch_trn = int(x_train.shape[0]/size_trn)\n",
    "num_batch_per_epoch_test = int(x_test.shape[0]/size_test)\n",
    "index_trn = np.random.permutation(num_batch_per_epoch_trn)\n",
    "index_test = np.random.permutation(num_batch_per_epoch_test)\n",
    "for i in range(num_iter):\n",
    "    i_trn = index_trn[i%num_batch_per_epoch_trn]\n",
    "    i_test = index_test[i%num_batch_per_epoch_test]\n",
    "    \n",
    "    comb_features = np.concatenate((x_train[(size_trn*i_trn):size_trn*(i_trn+1)],\n",
    "                                   Test[(size_test*i_test):size_test*(i_test+1)]),axis=0)\n",
    "    comb_labels = np.concatenate((y_train[(size_trn*i_trn):size_trn*(i_trn+1)],\n",
    "                                 y_pseudo[:,0][(size_test*i_test):size_test*(i_test+1)]), axis=0)\n",
    "    \n",
    "    model.train_on_batch(comb_features, comb_labels)\n",
    "    \n",
    "    if (i+1)%num_batch_per_epoch_trn == 0:\n",
    "        index_trn = np.random.permutation(num_batch_per_epoch_trn)\n",
    "    if (i+1)%num_batch_per_epoch_test == 0:\n",
    "        index_test = np.random.permutation(num_batch_per_epoch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1203 samples, validate on 401 samples\n",
      "Epoch 1/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.4848e-05 - acc: 1.0000Epoch 00000: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.4670e-05 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.8853\n",
      "Epoch 2/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.3299e-05 - acc: 1.0000Epoch 00001: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.2996e-05 - acc: 1.0000 - val_loss: 0.6098 - val_acc: 0.8853\n",
      "Epoch 3/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 3.8084e-05 - acc: 1.0000Epoch 00002: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 3.7628e-05 - acc: 1.0000 - val_loss: 0.6173 - val_acc: 0.8853\n",
      "Epoch 4/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.9520e-05 - acc: 1.0000Epoch 00003: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.9331e-05 - acc: 1.0000 - val_loss: 0.6238 - val_acc: 0.8853\n",
      "Epoch 5/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.9825e-05 - acc: 1.0000Epoch 00004: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.9420e-05 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.8853\n",
      "Epoch 6/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.9555e-05 - acc: 1.0000Epoch 00005: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.9567e-05 - acc: 1.0000 - val_loss: 0.6136 - val_acc: 0.8878\n",
      "Epoch 7/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.2499e-05 - acc: 1.0000Epoch 00006: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.2378e-05 - acc: 1.0000 - val_loss: 0.6168 - val_acc: 0.8853\n",
      "Epoch 8/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.1903e-05 - acc: 1.0000Epoch 00007: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.1888e-05 - acc: 1.0000 - val_loss: 0.6189 - val_acc: 0.8878\n",
      "Epoch 9/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.3402e-05 - acc: 1.0000Epoch 00008: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.3226e-05 - acc: 1.0000 - val_loss: 0.6212 - val_acc: 0.8878\n",
      "Epoch 10/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.8494e-05 - acc: 1.0000Epoch 00009: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.8337e-05 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8853\n",
      "Epoch 11/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.7014e-05 - acc: 1.0000Epoch 00010: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.6933e-05 - acc: 1.0000 - val_loss: 0.6224 - val_acc: 0.8878\n",
      "Epoch 12/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.4734e-05 - acc: 1.0000Epoch 00011: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.4881e-05 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 0.8853\n",
      "Epoch 13/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.8768e-05 - acc: 1.0000Epoch 00012: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.8985e-05 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 0.8903\n",
      "Epoch 14/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 2.3560e-05 - acc: 1.0000Epoch 00013: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 2.3368e-05 - acc: 1.0000 - val_loss: 0.6325 - val_acc: 0.8853\n",
      "Epoch 15/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.5400e-05 - acc: 1.0000Epoch 00014: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.5330e-05 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.8853\n",
      "Epoch 16/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.5852e-05 - acc: 1.0000Epoch 00015: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.6199e-05 - acc: 1.0000 - val_loss: 0.6314 - val_acc: 0.8828\n",
      "Epoch 17/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.2629e-05 - acc: 1.0000Epoch 00016: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.2986e-05 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.8903\n",
      "Epoch 18/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.3670e-05 - acc: 1.0000Epoch 00017: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.3532e-05 - acc: 1.0000 - val_loss: 0.6354 - val_acc: 0.8853\n",
      "Epoch 19/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.1800e-05 - acc: 1.0000Epoch 00018: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.8212e-05 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.8878\n",
      "Epoch 20/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.7927e-05 - acc: 1.0000Epoch 00019: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.7672e-05 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.8828\n",
      "Epoch 21/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.3230e-05 - acc: 1.0000Epoch 00020: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.3053e-05 - acc: 1.0000 - val_loss: 0.6450 - val_acc: 0.8828\n",
      "Epoch 22/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.3770e-05 - acc: 1.0000Epoch 00021: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.3615e-05 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8828\n",
      "Epoch 23/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.1751e-05 - acc: 1.0000Epoch 00022: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.2051e-05 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.8853\n",
      "Epoch 24/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.1349e-05 - acc: 1.0000Epoch 00023: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.1331e-05 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.8828\n",
      "Epoch 25/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.4456e-05 - acc: 1.0000Epoch 00024: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.4444e-05 - acc: 1.0000 - val_loss: 0.6476 - val_acc: 0.8828\n",
      "Epoch 26/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.2413e-05 - acc: 1.0000Epoch 00025: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.2328e-05 - acc: 1.0000 - val_loss: 0.6481 - val_acc: 0.8853\n",
      "Epoch 27/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.1499e-05 - acc: 1.0000Epoch 00026: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.1462e-05 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.8853\n",
      "Epoch 28/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.1525e-05 - acc: 1.0000Epoch 00027: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.1473e-05 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.8853\n",
      "Epoch 29/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.2041e-05 - acc: 1.0000Epoch 00028: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.3361e-05 - acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.8853\n",
      "Epoch 30/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 9.4982e-06 - acc: 1.0000Epoch 00029: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 9.5704e-06 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.8828\n",
      "Epoch 31/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.0984e-05 - acc: 1.0000Epoch 00030: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.2115e-05 - acc: 1.0000 - val_loss: 0.6531 - val_acc: 0.8853\n",
      "Epoch 32/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.0588e-05 - acc: 1.0000Epoch 00031: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.0430e-05 - acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.8853\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.0833e-05 - acc: 1.0000Epoch 00032: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.0703e-05 - acc: 1.0000 - val_loss: 0.6565 - val_acc: 0.8853\n",
      "Epoch 34/40\n",
      "1184/1203 [============================>.] - ETA: 0s - loss: 1.9248e-05 - acc: 1.0000Epoch 00033: val_acc did not improve\n",
      "1203/1203 [==============================] - 1s - loss: 1.9014e-05 - acc: 1.0000 - val_loss: 0.6702 - val_acc: 0.8853\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40b81b7898>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0\n",
    "model.fit(x_train, y_train, batch_size=32,epochs=40,callbacks=[check,early],validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8384/8424 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = ID\n",
    "submission['is_iceberg'] = pred\n",
    "submission.to_csv('submissions_pseudo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pseduo_labelling didnot work. \n",
    "Got 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203, 75, 75, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 75, 75, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pseudo[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
