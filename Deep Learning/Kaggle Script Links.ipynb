{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Icebergs and Ships EDA and Augmentation\n",
    "\n",
    "https://www.kaggle.com/asindico/icebergs-and-ships-eda-and-augmentation\n",
    "\n",
    "* using fast.ai\n",
    "\n",
    "https://github.com/groverpr/deep-learning/blob/master/image_comp_1_2.ipynb\n",
    "\n",
    "* GETTING COLOR COMPOSITES\n",
    "\n",
    "https://www.kaggle.com/keremt/getting-color-composites\n",
    "\n",
    "* Self Optimized CNN using Bayesian\n",
    "\n",
    "https://www.kaggle.com/huseinzol05/self-optimized-cnn-using-bayesian\n",
    "\n",
    "* Image Generator Augmentation and ConvNet\n",
    "https://www.kaggle.com/samuelsujith/image-generator-augmentation-and-convnet/code\n",
    "\n",
    "* Keras Dropout ensemble ( I need to use it again for summing)\n",
    "https://www.kaggle.com/alexandrudaia/keras-dropout-ensemble\n",
    "\n",
    "* Regulized Net and HE init30 neurons\n",
    "https://www.kaggle.com/alexandrudaia/regulized-net-and-he-init30-neurons\n",
    "\n",
    "* Lets try CapsuleNet\n",
    "https://www.kaggle.com/jasonbenner/lets-try-capsulenet/code\n",
    "\n",
    "\n",
    "* Fork of Fork of Myopic research ( excellent Images and exploration)\n",
    "https://www.kaggle.com/plarmuseau/fork-of-fork-of-myopic-research\n",
    "\n",
    "* Use Pretrained Model in Keras with Statoil dataset\n",
    "https://www.kaggle.com/sudosudoohio/use-pretrained-model-in-keras-with-statoil-dataset\n",
    "uses logistic,models from kaggle, xgboost\n",
    "\n",
    "* Keras Inception + Xception (0.47)\n",
    "https://www.kaggle.com/yangpeiwen/keras-inception-xception-0-47\n",
    "\n",
    "https://www.kaggle.com/jaredarcilla/invasive-species-inception\n",
    "\n",
    "https://www.kaggle.com/jamesrequa/keras-k-fold-inception-v3-1st-place-lb-0-99770\n",
    "(simple transfer learning)\n",
    "\n",
    "* Basic ResNet50 with composites 0.2502LB\n",
    "https://www.kaggle.com/jasonbenner/basic-resnet50-with-composites-0-2502lb\n",
    "use resnet instead of inceptionV3\n",
    "\n",
    "* Feature Extraction by ResNet (keras\n",
    "https://www.kaggle.com/cttsai/feature-extraction-by-resnet-keras\n",
    "To extract features by ResNet50 then can be further trained by XGBoost\n",
    "* Keras ResNet with image augmentation\n",
    "https://www.kaggle.com/strali/keras-resnet-with-image-augmentation\n",
    "to do plots afterwards\n",
    "\n",
    "* Using feature creation and modelling\n",
    "https://www.kaggle.com/the1owl/mr-freeze-s-ocean\n",
    "\n",
    "## Planet: understanding the Amazon from space ( new competition)\n",
    "Multi-label problem and not multi class\n",
    "* Keras VGG19 [0.93028 Private LB]\n",
    "\n",
    "https://www.kaggle.com/petrosgk/keras-vgg19-0-93028-private-lb\n",
    "Ensemble different models ( try this)\n",
    "\n",
    "* End-to-End ResNet50 with TTA [LB ~0.93] : test time augmentation (TTA)\n",
    "\n",
    "https://www.kaggle.com/sashakorekov/end-to-end-resnet50-with-tta-lb-0-93\n",
    "\n",
    "https://gh.mltrainings.ru/presentations/Mushinskiy_KaggleCarvanaImageMasking%20Challenge_2017.pdf\n",
    "\n",
    "https://github.com/rwightman/pytorch-planet-amazon\n",
    "\n",
    "https://towardsdatascience.com/my-first-kaggle-competition-9d56d4773607\n",
    "\n",
    "https://www.kaggle.com/shuyuan00/resnet50-with-0-985lb\n",
    "\n",
    "* [0.92837 on private LB] Solution with Keras\n",
    "\n",
    "https://github.com/EKami/planet-amazon-deforestation/blob/master/notebooks/amazon_forest_notebook.py\n",
    "\n",
    "* Multilabel Classification & Rainforest EDA\n",
    "\n",
    "https://www.kaggle.com/philschmidt/multilabel-classification-rainforest-eda\n",
    "Excellent EDA\n",
    "* Getting started with the data - now with docs!\n",
    "https://www.kaggle.com/robinkraft/getting-started-with-the-data-now-with-docs\n",
    "\n",
    "https://www.kaggle.com/bhuvaneshwaran/invasive-species-monitoring-keras\n",
    "\n",
    "https://www.kaggle.com/netzone/visualization-using-cv2-and-keras-starter\n",
    "\n",
    "https://github.com/planetlabs/planet-amazon-deforestation/blob/master/planet_chip_examples.ipynb\n",
    "\n",
    "https://www.kaggle.com/bkamphaus/exploratory-image-analysis\n",
    "\n",
    "https://www.kaggle.com/the1owl/stitch-and-predict\n",
    "\n",
    "Excellent kernel for some basic manipulation of the images and label files\n",
    "\n",
    "* XGB Starter\n",
    "https://www.kaggle.com/opanichev/xgb-starter\n",
    " XGB starter\n",
    " \n",
    "https://www.kaggle.com/the1owl/fractals-of-nature-blend-0-90050\n",
    " \n",
    "* Starting Kit for PyTorch Deep Learning\n",
    "https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning\n",
    "\n",
    "https://www.kaggle.com/idv2005/pytorch-starter-lb-0-988\n",
    "\n",
    "Exceelent tutorial for pytorch\n",
    "\n",
    "\n",
    "## Invasive Species Monitoring\n",
    "https://www.kaggle.com/c/invasive-species-monitoring\n",
    "\n",
    "* Keras k-fold Inception V3 (1st place LB 0.99770)\n",
    "https://www.kaggle.com/jamesrequa/keras-k-fold-inception-v3-1st-place-lb-0-99770\n",
    "\n",
    "\n",
    "* use Keras pre-trained VGG16 acc 98%\n",
    "\n",
    "https://www.kaggle.com/crequena/starter-s-pack-for-invasives-detection\n",
    "\n",
    "https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98\n",
    "\n",
    "https://www.kaggle.com/chmaxx/finetune-vgg16-0-97-with-minimal-effort\n",
    "\n",
    "Learned from official Keras blog tutorial\n",
    "\n",
    "* Inception v3 and k-fold in Python (0.98996)\n",
    "https://www.kaggle.com/algila/inception-v3-and-k-fold-in-python-0-98996\n",
    "\n",
    "Kfold--easy\n",
    "\n",
    "* Features and k-means\n",
    "\n",
    "https://www.kaggle.com/the1owl/big-fish-eats-little-fish-deep-koral-reefs/code\n",
    "\n",
    "* Tensorflow VGG Pretrained\n",
    "https://www.kaggle.com/ardiya/tensorflow-vgg-pretrained\n",
    "\n",
    "https://www.kaggle.com/patilpramod2157/transfer-learning-using-inception-resnet-v2\n",
    "\n",
    "https://www.kaggle.com/mbeierling/retraining-inception-v3\n",
    "\n",
    "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0\n",
    "Google tutorial\n",
    "\n",
    "* Finetune VGG16: 0.97% with minimal effort\n",
    "https://www.kaggle.com/chmaxx/finetune-vgg16-0-97-with-minimal-effort\n",
    "\n",
    "Good - Try it\n",
    "\n",
    "\n",
    "## Carvana Image Masking Challenge\n",
    "https://www.kaggle.com/c/carvana-image-masking-challenge\n",
    "\n",
    "* Visualization\n",
    "https://www.kaggle.com/vfdev5/data-visualization\n",
    "\n",
    "https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "\n",
    "https://www.kaggle.com/zfturbo/baseline-optimal-mask\n",
    "\n",
    "https://www.kaggle.com/gaborfodor/augmentation-methods ( excellent augmentation kernel -- )\n",
    "\n",
    "https://www.kaggle.com/vfdev5/pil-vs-opencv\n",
    "\n",
    "https://www.kaggle.com/ironbar/getting-a-meaning-of-the-score (dice score)\n",
    "\n",
    "https://www.kaggle.com/the1owl/zoom-zoom-zoom\n",
    "\n",
    "https://www.kaggle.com/ironbar/getting-a-meaning-of-the-score\n",
    "\n",
    "https://www.kaggle.com/hackerpoet/ufo-fusion-reactor-art (Good visualization )\n",
    "\n",
    "* Keras\n",
    "\n",
    "https://www.kaggle.com/bguberfain/naive-keras\n",
    "\n",
    "https://www.kaggle.com/ecobill/u-nets-with-keras ( U-nets with Keras )\n",
    "\n",
    "https://www.kaggle.com/lyakaap/weighing-boundary-pixels-loss-script-by-keras2 ( vanilla bce & dice loss )\n",
    "\n",
    "* h5py caching for fast data access\n",
    "https://www.kaggle.com/arsenyinfo/h5py-caching-for-fast-data-access\n",
    "\n",
    "https://www.kaggle.com/arseni/h5py-dataset-caching-with-shuffled-batch-generator\n",
    "\n",
    "* How does the image scale affect dice?\n",
    "https://www.kaggle.com/uiiurz1/how-does-the-image-scale-affect-dice\n",
    "\n",
    "* Even Faster Run Length Encoder\n",
    "https://www.kaggle.com/hackerpoet/even-faster-run-length-encoder\n",
    "\n",
    "https://www.kaggle.com/paulorzp/fast-run-length-encode\n",
    "\n",
    "* pytorch\n",
    "\n",
    "https://github.com/EKami/carvana-challenge\n",
    "\n",
    "https://www.kaggle.com/ekami66/clear-documented-a-to-z-code\n",
    "\n",
    "\n",
    "* Tpot\n",
    "\n",
    "https://www.kaggle.com/loveall/tpot-on-cervicalcancer-top10-factors\n",
    "\n",
    "* Gradient weights\n",
    "\n",
    "https://www.kaggle.com/pavelgonchar/gradient-weights\n",
    "\n",
    "## CIFAR-10 - Object Recognition in Images\n",
    "https://www.kaggle.com/c/cifar-10\n",
    "\n",
    "\n",
    "## Intel & MobileODT Cervical Cancer Screening\n",
    "\n",
    "https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
