{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is a type of unsupervised learning that automatically forms clusters of\n",
    "similar things. It’s like automatic classification. You can cluster almost anything, and\n",
    "the more similar the items are in the cluster, the better your clusters are.It’s called kmeans\n",
    "because it finds k unique clusters, and the center of each cluster is the mean of\n",
    "the values in that cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference from classification is that in classification\n",
    "you know what you’re looking for. That’s not the case in clustering. Clustering is\n",
    "sometimes called unsupervised classification because it produces the same result as classification\n",
    "but without having predefined classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means clustering\n",
    "\n",
    "Pros: Easy to implement\n",
    "\n",
    "Cons: Can converge at local minima; slow on very large datasets\n",
    "\n",
    "Works with: Numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "k-means is an algorithm that will find k clusters for a given dataset. The number of\n",
    "clusters k is user defined. Each cluster is described by a single point known as the\n",
    "centroid. Centroid means it’s at the center of all the points in the cluster.\n",
    "\n",
    "First, the k centroids are randomly assigned\n",
    "to a point. Next, each point in the dataset is assigned to a cluster. The assignment is done\n",
    "by finding the closest centroid and assigning the point to that cluster. After this step, the\n",
    "centroids are all updated by taking the mean value of all the points in that cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General approach to k-means clustering\n",
    "\n",
    "1. Collect: Any method.\n",
    "\n",
    "2. Prepare: Numeric values are needed for a distance calculation, and nominal values\n",
    "can be mapped into binary values for distance calculations.\n",
    "\n",
    "3. Analyze: Any method.\n",
    "\n",
    "4. Train: Doesn’t apply to unsupervised learning.\n",
    "\n",
    "5. Test: Apply the clustering algorithm and inspect the results. Quantitative error\n",
    "measurements such as sum of squared error (introduced later) can be used.\n",
    "\n",
    "6. Use: Anything you wish. Often, the clusters centers can be treated as representative\n",
    "data of the whole cluster to make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "def loadDataSet(fileName):      #general function to parse tab -delimited floats\n",
    "    dataMat = []                #assume last column is target value\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = list(map(float,curLine)) #map all elements to float()\n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distEclud(), calculates the Euclidean distance between two\n",
    "vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distEclud(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2))) #la.norm(vecA-vecB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randCent(), which creates a set of k random\n",
    "centroids for a given dataset. The random centroids need to be within the\n",
    "bounds of the dataset. This is accomplished by finding the minimum and maximum\n",
    "values of each dimension in the dataset. Random values from 0 to 1.0 are then chosen\n",
    "and scaled by the range and minimum value to ensure that the random points are\n",
    "within the bounds of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randCent(dataSet, k):\n",
    "    n = shape(dataSet)[1]\n",
    "    centroids = mat(zeros((k,n)))#create centroid mat\n",
    "    for j in range(n):#create random cluster centers, within bounds of each dimension\n",
    "        minJ = min(dataSet[:,j])\n",
    "        rangeJ = float(max(dataSet[:,j]) - minJ)\n",
    "        centroids[:,j] = mat(minJ + rangeJ * random.rand(k,1))\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datMat=mat(loadDataSet('testSet.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-5.379713]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(datMat[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 4.838138]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(datMat[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.49376032, -3.45217237],\n",
       "        [-4.91894502,  4.29912873]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randCent(datMat, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.184632816681332"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distEclud(datMat[0], datMat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will create k centroids, then assign each point to\n",
    "the closest centroid, and then recalculate the centroids. This process will repeat\n",
    "until the points stop changing clusters.\n",
    "\n",
    "The function kMeans() accepts four\n",
    "input parameters. The dataset and the number of clusters to generate are the only\n",
    "required parameters. A function to use as the distance metric is optional, and a function\n",
    "to create the initial centroids is also optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = mat(zeros((m,2)))#create mat to assign data points \n",
    "                                      #to a centroid, also holds SE of each point\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):#for each data point assign it to the closest centroid\n",
    "            minDist = inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex,minDist**2\n",
    "        print (centroids)\n",
    "        for cent in range(k):#recalculate centroids\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0].A==cent)[0]]#get all the point in this cluster\n",
    "            centroids[cent,:] = mean(ptsInClust, axis=0) #assign centroid to mean \n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.80379317  4.37870356]\n",
      " [ 2.84658746 -2.43426653]\n",
      " [-4.73100168 -1.5398105 ]\n",
      " [ 3.51363175  3.78765925]]\n",
      "[[-0.22833395  3.24660795]\n",
      " [ 2.65077367 -2.79019029]\n",
      " [-3.49409433 -1.28852678]\n",
      " [ 3.19820509  2.68632255]]\n",
      "[[-1.95594284  3.09788074]\n",
      " [ 2.65077367 -2.79019029]\n",
      " [-3.4859745  -2.31300105]\n",
      " [ 2.77216939  3.05357672]]\n",
      "[[-2.46154315  2.78737555]\n",
      " [ 2.65077367 -2.79019029]\n",
      " [-3.53973889 -2.89384326]\n",
      " [ 2.6265299   3.10868015]]\n"
     ]
    }
   ],
   "source": [
    "myCentroids, clustAssing = kMeans(datMat,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-means converges on a local minimum, not a global minimum.\n",
    "\n",
    "One metric for the quality of your cluster assignments you can use is the SSE, or sum\n",
    "of squared error. This is the sum of the values in column 1 of clusterAssment in listing\n",
    "10.2. A lower SSE means that points are closer to their centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the problem of poor clusters because of k-means getting caught in a\n",
    "local minimum,you could calculate distances between all\n",
    "centroids and merge the closest two. or the second method would require merging two\n",
    "clusters and then calculating the total SSE. You’d have to repeat this for all pairs of\n",
    "clusters to find the best pair to merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bisecting k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with all the points in one cluster\n",
    "\n",
    "While the number of clusters is less than k\n",
    "\n",
    "    for every cluster\n",
    "        measure total error\n",
    "        perform k-means clustering with k=2 on the given cluster\n",
    "        measure total error after k-means has split the cluster in two\n",
    "    choose the cluster split that gives the lowest error and commit this split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of thinking about this is to choose the cluster with the largest SSE and\n",
    "split it and then repeat until you get to the user-defined number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Arguments are a dataset, the number of clusters you want, and a distance measure, and it gives you the\n",
    "clusters. You can change the distance metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biKmeans(dataSet, k, distMeas=distEclud):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = mat(zeros((m,2)))\n",
    "    centroid0 = mean(dataSet, axis=0).tolist()[0]\n",
    "    centList =[centroid0] #create a list with one centroid\n",
    "    for j in range(m):#calc initial Error\n",
    "        clusterAssment[j,1] = distMeas(mat(centroid0), dataSet[j,:])**2\n",
    "    while (len(centList) < k):\n",
    "        lowestSSE = inf\n",
    "        for i in range(len(centList)):\n",
    "            ptsInCurrCluster = dataSet[nonzero(clusterAssment[:,0].A==i)[0],:]#get the data points currently in cluster i\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)\n",
    "            sseSplit = sum(splitClustAss[:,1])#compare the SSE to the currrent minimum\n",
    "            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:,0].A!=i)[0],1])\n",
    "            print (\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        bestClustAss[nonzero(bestClustAss[:,0].A == 1)[0],0] = len(centList) #change 1 to 3,4, or whatever\n",
    "        bestClustAss[nonzero(bestClustAss[:,0].A == 0)[0],0] = bestCentToSplit\n",
    "        print ('the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print ('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0]#replace a centroid with two best centroids \n",
    "        centList.append(bestNewCents[1,:].tolist()[0])\n",
    "        clusterAssment[nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss#reassign new clusters, and SSE\n",
    "    return mat(centList), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datMat3=mat(loadDataSet('testSet2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.45981238 -0.06831254]\n",
      " [ 2.80083722  0.93681815]]\n",
      "[[-0.60606057 -2.27031783]\n",
      " [ 0.12097373  3.39830046]]\n",
      "[[-0.45965615 -2.7782156 ]\n",
      " [-0.00675605  3.22710297]]\n",
      "sseSplit, and notSplit:  453.033489581 0.0\n",
      "the bestCentToSplit is:  0\n",
      "the len of bestClustAss is:  60\n",
      "[[-0.4259001  -3.74455194]\n",
      " [-1.17090446 -1.58230269]]\n",
      "[[-0.11329936 -3.20075614]\n",
      " [-1.267822   -1.79228767]]\n",
      "[[ -7.11923077e-04  -3.21792031e+00]\n",
      " [ -1.31198114e+00  -1.96162114e+00]]\n",
      "[[ 0.07973025 -3.24942808]\n",
      " [-1.26873575 -2.07139688]]\n",
      "[[ 0.19848727 -3.24320436]\n",
      " [-1.26405367 -2.209896  ]]\n",
      "[[ 0.2642961 -3.3057243]\n",
      " [-1.1836084 -2.2507069]]\n",
      "[[ 0.35496167 -3.36033556]\n",
      " [-1.12616164 -2.30193564]]\n",
      "sseSplit, and notSplit:  12.7532631369 423.876240137\n",
      "[[ 1.54731261  2.01806565]\n",
      " [-1.46292794  3.53461672]]\n",
      "[[ 2.93386365  3.12782785]\n",
      " [-2.94737575  3.3263781 ]]\n",
      "sseSplit, and notSplit:  77.5922493178 29.1572494441\n",
      "the bestCentToSplit is:  1\n",
      "the len of bestClustAss is:  40\n"
     ]
    }
   ],
   "source": [
    "centList,myNewAssments= biKmeans(datMat3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
