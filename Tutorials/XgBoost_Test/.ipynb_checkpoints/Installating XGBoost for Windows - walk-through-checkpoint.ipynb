{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have the following software Windows10, 64 bit,Python 3.5 and Anaconda3.I tried many times to install XGBoost but somehow it never worked for me. \n",
    "Today I decided to make it happen and am sharing this post to help anyone else who is struggling with installing XGBoost for Windows.\n",
    "\n",
    "XGBoost is short for “Extreme Gradient Boosting”.XGBoost is an optimized distributed gradient boosting system designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. \n",
    "\n",
    "XGBoost provides a parallel tree boosting(also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. It is one of the most frequently used package to win machine learning challenges.\n",
    "\n",
    "[Reference Paper](http://dmlc.cs.washington.edu/data/pdf/XGBoostArxiv.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I followed from the steps from this discussion at [stackoverflow](http://stackoverflow.com/questions/33749735/how-to-install-xgboost-package-in-python-windows-platform):\n",
    "\n",
    "1. Download and install MinGW-64: http://sourceforge.net/projects/mingw-w64/\n",
    "2. On the first screen of the install prompt make sure you set the Architecture to x86_64 and the Threads to win32\n",
    "3. I installed to C:\\mingw64 (to avoid spaces in the file path) so I added this to my PATH environment variable: C:\\mingw64\\mingw64\\bin\n",
    "4. I also noticed that the make utility that is included in bin\\mingw64 is called mingw32-make so to simplify things I just renamed this to make\n",
    "5. Open a Windows command prompt and type gcc. You should see something like \"fatal error: no input file\"\n",
    "6. Next type make. You should see something like \"No targets specified and no makefile found\"\n",
    "6. Type git. If you don't have git, install it and add it to your PATH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the source code run these lines:\n",
    "\n",
    "1. cd c:\\\n",
    "2. git clone --recursive https://github.com/dmlc/xgboost\n",
    "3. cd xgboost\n",
    "4. git submodule init\n",
    "5. git submodule update\n",
    "6. cp make/mingw64.mk config.mk\n",
    "7. make -j4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install the Python package, do the following:\n",
    "\n",
    "1. cd python-package\n",
    "2. python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it worked on my Python Interpreter. However, when I tried in Anaconda it failed to import xgboost module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another excellent [post](https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en) which I followed to finish the installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Anaconda simply use the Anaconda Prompt and go to C:\\xgboost\\python-package . This points to the python-package directory of XGBoost. Then type C:\\xgboost\\python-package>python setup.py install\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we open a jupyter notebook and add the path to the g++ runtime libraries to the os environment path variable with:\n",
    "\n",
    "import os\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us try XGBoost for a simple tutorial.\n",
    "\n",
    "I followed the [tutorial](http://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/).\n",
    "\n",
    "Download this [dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data) and place it into your current working directory with the file name “pima-indians-diabetes.csv“."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import xgboost\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the CSV file as a NumPy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = numpy.loadtxt('pima-indians-diabetes.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the columns (attributes or features) of the dataset into input patterns (X) and output patterns (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the X and Y data into a training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost provides a wrapper class to allow models to be treated like classifiers or regressors in the scikit-learn framework.The XGBoost model for classification is called XGBClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about the defaults for the XGBClassifier and XGBRegressor classes in the [XGBoost Python scikit-learn API](http://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn).\n",
    "\n",
    "You can learn more about the meaning of each parameter and how to configure them on the [XGBoost parameters page](http://xgboost.readthedocs.io/en/latest//parameter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions with XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the predictions made by XGBoost are probabilities. Because this is a binary classification problem, each prediction is the probability of the input pattern belonging to the first class. We can easily convert them to binary class values by rounding them to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.95%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this blog post will help Windows user and I am going to use XGBoost in my future machine learning endeavours. \n",
    "\n",
    "Do you have any questions about XGBoost or about this post? Ask your questions in the comments and I will do my best to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
