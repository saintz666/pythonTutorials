{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code snippets for Pandas\n",
    "import pandas as pd\n",
    "‘’’\n",
    "Reading Files, Selecting Columns, and Summarizing\n",
    "‘’’\n",
    "# reading in a file from local computer or directly from a URL\n",
    "# various file formats that can be read in out wrote out\n",
    "‘’’\n",
    "Format Type     Data Description      Reader           Writer\n",
    "text                  CSV            read_csv          to_csv\n",
    "text                 JSON            read_json         to_json\n",
    "text                 HTML            read_html         to_html\n",
    "text             Local clipboard  read_clipboard     to_clipboard\n",
    "binary             MS Excel          read_excel        to_excel\n",
    "binary            HDF5 Format        read_hdf           to_hdf\n",
    "binary           Feather Format     read_feather      to_feather\n",
    "binary              Msgpack         read_msgpack      to_msgpack\n",
    "binary               Stata           read_stata        to_stata\n",
    "binary                SAS             read_sas \n",
    "binary        Python Pickle Format   read_pickle       to_pickle\n",
    "SQL                   SQL             read_sql          to_sql\n",
    "SQL             Google Big Query      read_gbq          to_gbq\n",
    "‘’’\n",
    "#to read about different types of files, and further functionality of reading in files, visit: http://pandas.pydata.org/pandas-docs/version/0.20/io.html\n",
    "df = pd.read_csv(‘local_path/file.csv’)\n",
    "df = pd.read_csv(‘https://file_path/file.csv')\n",
    "# when reading in tables, can specify separators, and note a column to be used as index separators can include tabs (“\\t”), commas(“,”), pipes (“|”), etc.\n",
    "df = pd.read_table(‘https://file_path/file', sep=’|’, index_col=’column_x’)\n",
    "# examine the df data\n",
    "df           # print the first 30 and last 30 rows\n",
    "type(df)     # DataFrame\n",
    "df.head()    # print the first 5 rows\n",
    "df.head(10)  # print the first 10 rows\n",
    "df.tail()    # print the last 5 rows\n",
    "df.index     # “the index” (aka “the labels”)\n",
    "df.columns   # column names (which is “an index”)\n",
    "df.dtypes    # data types of each column\n",
    "df.shape     # number of rows and columns\n",
    "df.values    # underlying numpy array — df are stored as numpy arrays for effeciencies.\n",
    "# select a column\n",
    "df[‘column_y’]         # select one column\n",
    "type(df[‘column_y’])   # determine datatype of column (e.g., Series)\n",
    "df.column_y            # select one column using the DataFrame attribute — not effective if column names have spaces\n",
    "# summarize (describe) the DataFrame\n",
    "df.describe()          # describe all numeric columns\n",
    "df.describe(include=[‘object’]) # describe all object columns\n",
    "df.describe(include=’all’)      # describe all columns\n",
    "# summarize a Series\n",
    "df.column_y.describe()   # describe a single column\n",
    "df.column_z.mean()       # only calculate the mean\n",
    "df[“column_z”].mean()    # alternate method for calculating mean\n",
    " \n",
    "# count the number of occurrences of each value\n",
    "df.column_y.value_counts()   # most useful for categorical variables, but can also be used with numeric variables\n",
    "#filter df by one column, and print out values of another column\n",
    "#when using numeric values, no quotations\n",
    "df[df.column_y == “string_value”].column_z\n",
    "df[df.column_y == 20 ].column_z    \n",
    " \n",
    "# display only the number of rows of the ‘df’ DataFrame\n",
    "df.shape[0]\n",
    "# display the 3 most frequent occurances of column in ‘df’\n",
    "df.column_y.value_counts()[0:3]\n",
    "‘’’\n",
    "Filtering and Sorting\n",
    "‘’’\n",
    "# boolean filtering: only show df with column_z < 20\n",
    "filter_bool = df.column_z < 20    # create a Series of booleans…\n",
    "df[filter_bool]                # …and use that Series to filter rows\n",
    "df[filter_bool].describe()     # describes a data frame filtered by filter_bool\n",
    "df[df.column_z < 20]           # or, combine into a single step\n",
    "df[df.column_z < 20].column_x  # select one column from the filtered results\n",
    "df[df[“column_z”] < 20].column_x     # alternate method \n",
    "df[df.column_z < 20].column_x.value_counts()   # value_counts of resulting Series, can also use .mean(), etc. instead of .value_counts()\n",
    "# boolean filtering with multiple conditions; indexes are in square brackets, conditions are in parens\n",
    "df[(df.column_z < 20) & (df.column_y==’string’)] # ampersand for AND condition \n",
    "df[(df.column_z < 20) | (df.column_z > 60)] # pipe for OR condition\n",
    "# sorting\n",
    "df.column_z.order()          # sort a column\n",
    "df.sort_values(‘column_z’)   # sort a DataFrame by a single column\n",
    "df.sort_values(‘column_z’, ascending=False)     # use descending order instead\n",
    "# Sort dataframe by multiple columns\n",
    "df = df.sort([‘col1’,’col2',’col3'],ascending=[1,1,0]) \n",
    " \n",
    "# can also filter ‘df’ using pandas.Series.isin \n",
    "df[df.column_x.isin([“string_1”, “string_2”])]\n",
    "‘’’\n",
    "Renaming, Adding, and Removing Columns\n",
    "‘’’\n",
    "# rename one or more columns\n",
    "df.rename(columns={‘original_column_1’:’column_x’, ‘original_column_2’:’column_y’}, inplace=True) #saves changes \n",
    " \n",
    "# replace all column names (in place)\n",
    "new_cols = [‘column_x’, ‘column_y’, ‘column_z’]\n",
    "df.columns = new_cols\n",
    "# replace all column names when reading the file\n",
    "df = pd.read_csv(‘df.csv’, header=0, names=new_cols)\n",
    "# add a new column as a function of existing columns\n",
    "df[‘new_column_1’] = df.column_x + df.column_y\n",
    "df[‘new_column_2’] = df.column_x * 1000   #can create new columns without for loops\n",
    "# removing columns\n",
    "df.drop(‘column_x’, axis=1)   # axis=0 for rows, 1 for columns — does not drop in place\n",
    "df.drop([‘column_x’, ‘column_y’], axis=1, inplace=True) # drop multiple columns\n",
    "# Lower-case all DataFrame column names\n",
    "df.columns = map(str.lower, df.columns)\n",
    "# Even more fancy DataFrame column re-naming\n",
    "# lower-case all DataFrame column names (for example)\n",
    "df.rename(columns=lambda x: x.split(‘.’)[-1], inplace=True)\n",
    " \n",
    " \n",
    "‘’’\n",
    "Handling Missing Values\n",
    "‘’’\n",
    "# missing values are usually excluded by default\n",
    "df.column_x.value_counts()             # excludes missing values\n",
    "df.column_x.value_counts(dropna=False) # includes missing values\n",
    "# find missing values in a Series\n",
    "df.column_x.isnull()  # True if missing\n",
    "df.column_x.notnull() # True if not missing\n",
    "# use a boolean Series to filter DataFrame rows\n",
    "df[df.column_x.isnull()]  # only show rows where column_x is missing\n",
    "df[df.column_x.notnull()] # only show rows where column_x is not missing\n",
    "# understanding axes\n",
    "df.sum()       # sums “down” the 0 axis (rows)\n",
    "df.sum(axis=0) # equivalent (since axis=0 is the default)\n",
    "df.sum(axis=1) # sums “across” the 1 axis (columns)\n",
    "# adding booleans\n",
    "pd.Series([True, False, True])       # create a boolean Series\n",
    "pd.Series([True, False, True]).sum() # converts False to 0 and True to 1\n",
    "# find missing values in a DataFrame\n",
    "df.isnull() # DataFrame of booleans\n",
    "df.isnull().sum() # count the missing values in each column\n",
    "# drop missing values\n",
    "df.dropna(inplace=True)   # drop a row if ANY values are missing, defaults to rows, but can be applied to columns with axis=1\n",
    "df.dropna(how=’all’, inplace=True)  # drop a row only if ALL values are missing\n",
    "# fill in missing values\n",
    "df.column_x.fillna(value=’NA’, inplace=True) \n",
    "# fill in missing values with ‘NA’\n",
    "# value does not have to equal a string — can be set as some calculated value like df.column_x.mode(), or just a number like 0\n",
    " \n",
    " \n",
    "# turn off the missing value filter\n",
    "df = pd.read_csv(‘df.csv’, header=0, names=new_cols, na_filter=False)\n",
    "‘’’\n",
    "Split-Apply-Combine\n",
    "Diagram: http://i.imgur.com/yjNkiwL.png\n",
    "‘’’\n",
    "# for each value in column_x, calculate the mean column_y \n",
    "df.groupby(‘column_x’).column_y.mean()\n",
    "# for each value in column_x, count the number of occurrences\n",
    "df.column_x.value_counts()\n",
    "# for each value in column_x, describe column_y\n",
    "df.groupby(‘column_x’).column_y.describe()\n",
    "# similar, but outputs a DataFrame and can be customized\n",
    "df.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’])\n",
    "df.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’]).sort_values(‘mean’)\n",
    "# if you don’t specify a column to which the aggregation function should be applied, it will be applied to all numeric columns\n",
    "df.groupby(‘column_x’).mean()\n",
    "df.groupby(‘column_x’).describe()\n",
    "# can also groupby a list of columns, i.e., for each combination of column_x and column_y, calculate the mean column_z\n",
    "df.groupby([“column_x”,”column_y”]).column_z.mean()\n",
    "#to take groupby results out of hierarchical index format (e.g., present as table), use .unstack() method\n",
    "df.groupby(“column_x”).column_y.value_counts().unstack()\n",
    "#conversely, if you want to transform a table into a hierarchical index, use the .stack() method\n",
    "df.stack()\n",
    "‘’’\n",
    "Selecting Multiple Columns and Filtering Rows\n",
    "‘’’\n",
    "# select multiple columns\n",
    "my_cols = [‘column_x’, ‘column_y’]  # create a list of column names…\n",
    "df[my_cols]                   # …and use that list to select columns\n",
    "df[[‘column_x’, ‘column_y’]]  # or, combine into a single step — double brackets due to indexing a list.\n",
    "# use loc to select columns by name\n",
    "df.loc[:, ‘column_x’]    # colon means “all rows”, then select one column\n",
    "df.loc[:, [‘column_x’, ‘column_y’]]  # select two columns\n",
    "df.loc[:, ‘column_x’:’column_y’]     # select a range of columns (i.e., selects all columns including first through last specified)\n",
    "# loc can also filter rows by “name” (the index)\n",
    "df.loc[0, :]       # row 0, all columns\n",
    "df.loc[0:2, :]     # rows 0/1/2, all columns\n",
    "df.loc[0:2, ‘column_x’:’column_y’] # rows 0/1/2, range of columns\n",
    "# use iloc to filter rows and select columns by integer position\n",
    "df.iloc[:, [0, 3]]     # all rows, columns in position 0/3\n",
    "df.iloc[:, 0:4]        # all rows, columns in position 0/1/2/3\n",
    "df.iloc[0:3, :]        # rows in position 0/1/2, all columns\n",
    "#filtering out and dropping rows based on condition (e.g., where column_x values are null)\n",
    "drop_rows = df[df[“column_x”].isnull()]\n",
    "new_df = df[~df.isin(drop_rows)].dropna(how=’all’)\n",
    " \n",
    " \n",
    " \n",
    "‘’’\n",
    "Merging and Concatenating Dataframes\n",
    "‘’’ \n",
    "#concatenating two dfs together (just smooshes them together, does not pair them in any meaningful way) - axis=1 concats df2 to right side of df1; axis=0 concats df2 to bottom of df1\n",
    "new_df = pd.concat([df1, df2], axis=1)\n",
    "#merging dfs based on paired columns; columns do not need to have same name, but should match values; left_on column comes from df1, right_on column comes from df2\n",
    "new_df = pd.merge(df1, df2, left_on=’column_x’, right_on=’column_y’)\n",
    "#can also merge slices of dfs together, though slices need to include columns used for merging\n",
    "new_df = pd.merge(df1[[‘column_x1’, ‘column_x2’]], df2, left_on=’column_x2', right_on=’column_y’)\n",
    "#merging two dataframes based on shared index values (left is df1, right is df2)\n",
    "new_df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    " \n",
    " \n",
    "‘’’\n",
    "Other Frequently Used Features\n",
    "‘’’\n",
    "# map existing values to a different set of values\n",
    "df[‘column_x’] = df.column_y.map({‘F’:0, ‘M’:1})\n",
    "# encode strings as integer values (automatically starts at 0)\n",
    "df[‘column_x_num’] = df.column_x.factorize()[0]\n",
    "# determine unique values in a column\n",
    "df.column_x.nunique()   # count the number of unique values\n",
    "df.column_x.unique()    # return the unique values\n",
    "# replace all instances of a value in a column (must match entire value)\n",
    "df.column_y.replace(‘old_string’, ‘new_string’, inplace=True)\n",
    "#alter values in one column based on values in another column (changes occur in place)\n",
    "#can use either .loc or .ix methods\n",
    "df.loc[df[“column_x”] == 5, “column_y”] = 1\n",
    " \n",
    "df.ix[df.column_x == “string_value”, “column_y”] = “new_string_value”\n",
    "#transpose data frame (i.e. rows become columns, columns become rows)\n",
    "df.T\n",
    "# string methods are accessed via ‘str’\n",
    "df.column_y.str.upper() # converts to uppercase\n",
    "df.column_y.str.contains(‘value’, na=’False’) # checks for a substring, returns boolean series\n",
    "# convert a string to the datetime_column format\n",
    "df[‘time_column’] = pd.to_datetime_column(df.time_column)\n",
    "df.time_column.dt.hour   # datetime_column format exposes convenient attributes\n",
    "(df.time_column.max() — df.time_column.min()).days   # also allows you to do datetime_column “math”\n",
    "df[df.time_column > pd.datetime_column(2014, 1, 1)]   # boolean filtering with datetime_column format\n",
    "# setting and then removing an index, resetting index can help remove hierarchical indexes while preserving the table in its basic structure\n",
    "df.set_index(‘time_column’, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "# sort a column by its index\n",
    "df.column_y.value_counts().sort_index()\n",
    "# change the data type of a column\n",
    "df[‘column_x’] = df.column_x.astype(‘float’)\n",
    "# change the data type of a column when reading in a file\n",
    "pd.read_csv(‘df.csv’, dtype={‘column_x’:float})\n",
    "# create dummy variables for ‘column_x’ and exclude first dummy column\n",
    "column_x_dummies = pd.get_dummies(df.column_x).iloc[:, 1:]\n",
    "# concatenate two DataFrames (axis=0 for rows, axis=1 for columns)\n",
    "df = pd.concat([df, column_x_dummies], axis=1)\n",
    "‘’’\n",
    "Less Frequently Used Features\n",
    "‘’’\n",
    "# create a DataFrame from a dictionary\n",
    "pd.DataFrame({‘column_x’:[‘value_x1’, ‘value_x2’, ‘value_x3’], ‘column_y’:[‘value_y1’, ‘value_y2’, ‘value_y3’]})\n",
    "# create a DataFrame from a list of lists\n",
    "pd.DataFrame([[‘value_x1’, ‘value_y1’], [‘value_x2’, ‘value_y2’], [‘value_x3’, ‘value_y3’]], columns=[‘column_x’, ‘column_y’])\n",
    "# detecting duplicate rows\n",
    "df.duplicated()       # True if a row is identical to a previous row\n",
    "df.duplicated().sum() # count of duplicates\n",
    "df[df.duplicated()]   # only show duplicates\n",
    "df.drop_duplicates()  # drop duplicate rows\n",
    "df.column_z.duplicated()   # check a single column for duplicates\n",
    "df.duplicated([‘column_x’, ‘column_y’, ‘column_z’]).sum()  # specify columns for finding duplicates\n",
    "# Clean up missing values in multiple DataFrame columns\n",
    "df = df.fillna({\n",
    " ‘col1’: ‘missing’,\n",
    " ‘col2’: ‘99.999’,\n",
    " ‘col3’: ‘999’,\n",
    " ‘col4’: ‘missing’,\n",
    " ‘col5’: ‘missing’,\n",
    " ‘col6’: ‘99’\n",
    "})\n",
    "# Concatenate two DataFrame columns into a new, single column - (useful when dealing with composite keys, for example)\n",
    "df[‘newcol’] = df[‘col1’].map(str) + df[‘col2’].map(str)\n",
    "# Doing calculations with DataFrame columns that have missing values\n",
    "# In example below, swap in 0 for df[‘col1’] cells that contain null\n",
    "df[‘new_col’] = np.where(pd.isnull(df[‘col1’]),0,df[‘col1’]) + df[‘col2’]\n",
    " \n",
    "# display a cross-tabulation of two Series\n",
    "pd.crosstab(df.column_x, df.column_y)\n",
    "# alternative syntax for boolean filtering (noted as “experimental” in the documentation)\n",
    "df.query(‘column_z < 20’) # df[df.column_z < 20]\n",
    "df.query(“column_z < 20 and column_y==’string’”)  # df[(df.column_z < 20) & (df.column_y==’string’)]\n",
    "df.query(‘column_z < 20 or column_z > 60’)        # df[(df.column_z < 20) | (df.column_z > 60)]\n",
    "# Loop through rows in a DataFrame\n",
    "for index, row in df.iterrows():\n",
    " print index, row[‘column_x’]\n",
    "# Much faster way to loop through DataFrame rows if you can work with tuples\n",
    "for row in df.itertuples():\n",
    " print(row)\n",
    "# Get rid of non-numeric values throughout a DataFrame:\n",
    "for col in df.columns.values:\n",
    " df[col] = df[col].replace(‘[⁰-9]+.-’, ‘’, regex=True)\n",
    "# Change all NaNs to None (useful before loading to a db)\n",
    "df = df.where((pd.notnull(df)), None)\n",
    "# Split delimited values in a DataFrame column into two new columns\n",
    "df[‘new_col1’], df[‘new_col2’] = zip(*df[‘original_col’].apply(lambda x: x.split(‘: ‘, 1)))\n",
    "# Collapse hierarchical column indexes\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "# display the memory usage of a DataFrame\n",
    "df.info()         # total usage\n",
    "df.memory_usage() # usage by column\n",
    "# change a Series to the ‘category’ data type (reduces memory usage and increases performance)\n",
    "df[‘column_y’] = df.column_y.astype(‘category’)\n",
    "# temporarily define a new column as a function of existing columns\n",
    "df.assign(new_column = df.column_x + df.spirit + df.column_y)\n",
    "# limit which rows are read when reading in a file\n",
    "pd.read_csv(‘df.csv’, nrows=10)        # only read first 10 rows\n",
    "pd.read_csv(‘df.csv’, skiprows=[1, 2]) # skip the first two rows of data\n",
    "# randomly sample a DataFrame\n",
    "train = df.sample(frac=0.75, random_column_y=1) # will contain 75% of the rows\n",
    "test = df[~df.index.isin(train.index)] # will contain the other 25%\n",
    "# change the maximum number of rows and columns printed (‘None’ means unlimited)\n",
    "pd.set_option(‘max_rows’, None) # default is 60 rows\n",
    "pd.set_option(‘max_columns’, None) # default is 20 columns\n",
    "print df\n",
    "# reset options to defaults\n",
    "pd.reset_option(‘max_rows’)\n",
    "pd.reset_option(‘max_columns’)\n",
    "# change the options temporarily (settings are restored when you exit the ‘with’ block)\n",
    "with pd.option_context(‘max_rows’, None, ‘max_columns’, None):\n",
    " print df\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
